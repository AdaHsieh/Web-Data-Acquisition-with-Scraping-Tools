{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xef in position 3984: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-579578b2614a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word/neg1.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mnegative_words1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#### Join the two lexicon in one list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-579578b2614a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word/neg1.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mnegative_words1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#### Join the two lexicon in one list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xef in position 3984: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from textblob import TextBlob\n",
    "\n",
    "# emoticons list\n",
    "neg_emo = ['>:[', ':-(', ':(', ':-c', ':c', ':-<\\n', ':?C', ':<', ':-[', ':[', ':{', ':-||', ':@', \":'-(\", \":'(\", 'D:<', 'D:', 'D8', 'D;', 'D=', 'DX', 'v.v', \"D-':\", '>:O', ':-O', ':O', '∞o∞', '∞O∞', ':O', 'o_O', 'o_0', 'o.O', '8-0', '>:\\\\', '>:/', ':-/', ':-.', ':/', ':\\\\', '=/', '=\\\\', ':L', '=L', ':S', '>.<', ':-|', ':$', ':-X', ':X', ':-#', ':#', '>:)', '>;)', '>:-)', '}:-)', '}:)', '3:-)', '3:)', ':-&', ':&', '#-)', '%-)', '%)', ':-###..', ':###..', '<:-|', '</3', ':-\\\\\\\\', ':\\\\\\\\', ':-/', ':/', ')-:', '):', ';-(', ';(']\n",
    "pos_emo = [':-)', ':)', ':o)', ':]', ':3', ':c)',':>','=]','8)','=)',':}',':^)',':?)',':-D',':D','8-D','8D','x-D','xD','X-D','XD','=-D','=D','=-3','=3','B^D',\":-))\",'(-:','(:','B-)',';-)',';)',':-P',':P','<3',\":'-)\",\":')\",':*',':^*',\"('}{' )\",'*-)','*)',';-]',';]',';D',';^)',':-,','>:P','X-P','x-p','xp','XP',':-p',':p','=p',':-\\xde',':\\xde',':-b',':b','O:-)','0:-3','0:3 ','0:-)','0:)','0;^)','o/\\\\o','^5 ','>_>^ ^<_<','|;-)','|-O']\n",
    "\n",
    "# totalEmo: makes a list of the pos and neg emoticones\n",
    "totalEmo = pos_emo + neg_emo\n",
    "totalEmo2 = set(totalEmo)\n",
    "\n",
    "# _______________________________________\n",
    "# Punctuation marks to remove\n",
    "punc = (['{', '}', '\"'])\n",
    "exclude = set(punc)\n",
    "\n",
    "# _______________________________________\n",
    "#connect to Mongodb\n",
    "\n",
    "client = MongoClient()  \n",
    "# Connect to a Database:    <<<<<<<<< Modify:ENTER YOUR DB NAME\n",
    "db = client.tweetsdb_2\n",
    "\n",
    "# Connect to a Collection:  <<<<<<<<< Modify:ENTER YOUR COLLECTION NAME\n",
    "tweets = db.modtweet\n",
    "\n",
    "# Cleans the collection for the modified tweets - extra step\n",
    "db.pos_tweet.drop()\n",
    "db.neg_tweet.drop()\n",
    "db.neu_tweet.drop()\n",
    "\n",
    "# _______________________________________\n",
    "# Import Words for Classifier into a list\n",
    "\n",
    "### Lexicon from first source \n",
    "with open('word/pos.txt', 'r') as f:\n",
    "    positive_words = [line.strip() for line in f]\n",
    "    positive_words = [x.lower() for x in positive_words]\n",
    "\n",
    "with open('word/neg.txt', 'r') as f:\n",
    "    negative_words = [line.strip() for line in f]\n",
    "    negative_words = [x.lower() for x in negative_words]\n",
    "\n",
    "### Lexicon from Second source: Bing liu\n",
    "with open('word/pos1.txt', 'r') as f:\n",
    "    positive_words1 = [line.strip() for line in f]\n",
    "\n",
    "with open('word/neg1.txt', 'r') as f:\n",
    "    negative_words1 = [line.strip() for line in f]\n",
    "\n",
    "#### Join the two lexicon in one list:\n",
    "total_positive = positive_words + positive_words1\n",
    "total_negative = negative_words + negative_words1\n",
    "\n",
    "# _______________________________________\n",
    "# Make a list from the Collection for only the tweet :\n",
    "tw = tweets.find({},{'text':1,'_id':0})\n",
    "print('Working...')\n",
    "for x in tw:\n",
    "    \n",
    "    tw_string = x['text']\n",
    "    \n",
    "    # Remove punctuation:\n",
    "    # 1. Temporary emoticon variable storage\n",
    "    emoticonExt = ' '.join(ch for ch in totalEmo2 if ch in tw_string)\n",
    "\n",
    "    # 2. Remove Punctuation\n",
    "    json_string = ''.join(ch for ch in tw_string if ch not in exclude)\n",
    "\n",
    "    # 3. Temporary remove the emoticon\n",
    "    json_string = json_string +' '+ emoticonExt\n",
    "    emoticonExt = \"\"\n",
    "   \n",
    "    # _______________________________________\n",
    "    # First Classifier: Emoticon Classifier\n",
    "\n",
    "    raw_words = json_string.split(\" \")\n",
    "\n",
    "    positive_score1 = len([word for word in raw_words if word in pos_emo])\n",
    "    negative_score1 = len([word for word in raw_words if word in neg_emo])\n",
    "\n",
    "    total_score1 = positive_score1 - negative_score1\n",
    "    \n",
    "    if (total_score1 > 0):\n",
    "        #saving data to Positive Collection\n",
    "        db.pos_tweet.insert_one({\"text\":json_string})\n",
    "               \n",
    "    elif (total_score1 < 0):\n",
    "        #saving data to Negative Collection\n",
    "        db.neg_tweet.insert_one({\"text\":json_string})\n",
    "        \n",
    "    else: # go to next classifier\n",
    "        \n",
    "    # _______________________________________\n",
    "    # Second Classifier: Improved Polarity Classifier\n",
    "\n",
    "        positive_score2 = len([word for word in raw_words if word in total_positive])\n",
    "        negative_score2 = len([word for word in raw_words if word in total_negative])\n",
    "\n",
    "        total_score2 = positive_score2 - negative_score2\n",
    "        \n",
    "        if (total_score2 > 0):\n",
    "            #saving data to Positive Collection\n",
    "            db.pos_tweet.insert_one({\"text\":json_string})\n",
    "            \n",
    "        elif (total_score2 < 0):\n",
    "            #saving data to Negative Collection\n",
    "            db.neg_tweet.insert_one({\"text\":json_string})\n",
    "         \n",
    "        else: # go to next classifier\n",
    "            \n",
    "    # _______________________________________\n",
    "    # Third Classifier: Blob Classifier\n",
    "                        \n",
    "            tb = TextBlob(json_string)    \n",
    "            pol = tb.sentiment.polarity\n",
    "            if (pol > 0):\n",
    "                #saving data to Positive Collection\n",
    "                db.pos_tweet.insert_one({\"text\":json_string})\n",
    "               \n",
    "            elif (pol < 0):\n",
    "                #saving data to Negative Collection\n",
    "                db.neg_tweet.insert_one({\"text\":json_string})\n",
    "                                \n",
    "            else: \n",
    "                #saving data to Neutral Collection\n",
    "                db.neu_tweet.insert_one({\"text\":json_string})\n",
    "                     \n",
    "print('Done.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos1:  ['ABLE', 'ABUNDANCE', 'ABUNDANT', 'ACCLAIMED', 'ACCOMPLISH', 'ACCOMPLISHED', 'ACCOMPLISHES', 'ACCOMPLISHING', 'ACCOMPLISHMENT', 'ACCOMPLISHMENTS', 'ACHIEVE', 'ACHIEVED', 'ACHIEVEMENT', 'ACHIEVEMENTS', 'ACHIEVES', 'ACHIEVING', 'ADEQUATELY', 'ADVANCEMENT', 'ADVANCEMENTS', 'ADVANCES', 'ADVANCING', 'ADVANTAGE', 'ADVANTAGED', 'ADVANTAGEOUS', 'ADVANTAGEOUSLY', 'ADVANTAGES', 'ALLIANCE', 'ALLIANCES', 'ASSURE', 'ASSURED', 'ASSURES', 'ASSURING', 'ATTAIN', 'ATTAINED', 'ATTAINING', 'ATTAINMENT', 'ATTAINMENTS', 'ATTAINS', 'ATTRACTIVE', 'ATTRACTIVENESS', 'BEAUTIFUL', 'BEAUTIFULLY', 'BENEFICIAL', 'BENEFICIALLY', 'BENEFIT', 'BENEFITED', 'BENEFITING', 'BENEFITTED', 'BENEFITTING', 'BEST', 'BETTER', 'BOLSTERED', 'BOLSTERING', 'BOLSTERS', 'BOOM', 'BOOMING', 'BOOST', 'BOOSTED', 'BREAKTHROUGH', 'BREAKTHROUGHS', 'BRILLIANT', 'CHARITABLE', 'COLLABORATE', 'COLLABORATED', 'COLLABORATES', 'COLLABORATING', 'COLLABORATION', 'COLLABORATIONS', 'COLLABORATIVE', 'COLLABORATOR', 'COLLABORATORS', 'COMPLIMENT', 'COMPLIMENTARY', 'COMPLIMENTED', 'COMPLIMENTING', 'COMPLIMENTS', 'CONCLUSIVE', 'CONCLUSIVELY', 'CONDUCIVE', 'CONFIDENT', 'CONSTRUCTIVE', 'CONSTRUCTIVELY', 'COURTEOUS', 'CREATIVE', 'CREATIVELY', 'CREATIVENESS', 'CREATIVITY', 'DELIGHT', 'DELIGHTED', 'DELIGHTFUL', 'DELIGHTFULLY', 'DELIGHTING', 'DELIGHTS', 'DEPENDABILITY', 'DEPENDABLE', 'DESIRABLE', 'DESIRED', 'DESPITE', 'DESTINED', 'DILIGENT', 'DILIGENTLY', 'DISTINCTION', 'DISTINCTIONS', 'DISTINCTIVE', 'DISTINCTIVELY', 'DISTINCTIVENESS', 'DREAM', 'EASIER', 'EASILY', 'EASY', 'EFFECTIVE', 'EFFICIENCIES', 'EFFICIENCY', 'EFFICIENT', 'EFFICIENTLY', 'EMPOWER', 'EMPOWERED', 'EMPOWERING', 'EMPOWERS', 'ENABLE', 'ENABLED', 'ENABLES', 'ENABLING', 'ENCOURAGED', 'ENCOURAGEMENT', 'ENCOURAGES', 'ENCOURAGING', 'ENHANCE', 'ENHANCED', 'ENHANCEMENT', 'ENHANCEMENTS', 'ENHANCES', 'ENHANCING', 'ENJOY', 'ENJOYABLE', 'ENJOYABLY', 'ENJOYED', 'ENJOYING', 'ENJOYMENT', 'ENJOYS', 'ENTHUSIASM', 'ENTHUSIASTIC', 'ENTHUSIASTICALLY', 'EXCELLENCE', 'EXCELLENT', 'EXCELLING', 'EXCELS', 'EXCEPTIONAL', 'EXCEPTIONALLY', 'EXCITED', 'EXCITEMENT', 'EXCITING', 'EXCLUSIVE', 'EXCLUSIVELY', 'EXCLUSIVENESS', 'EXCLUSIVES', 'EXCLUSIVITY', 'EXEMPLARY', 'FANTASTIC', 'FAVORABLE', 'FAVORABLY', 'FAVORED', 'FAVORING', 'FAVORITE', 'FAVORITES', 'FRIENDLY', 'GAIN', 'GAINED', 'GAINING', 'GAINS', 'GOOD', 'GREAT', 'GREATER', 'GREATEST', 'GREATLY', 'GREATNESS', 'HAPPIEST', 'HAPPILY', 'HAPPINESS', 'HAPPY', 'HIGHEST', 'HONOR', 'HONORABLE', 'HONORED', 'HONORING', 'HONORS', 'IDEAL', 'IMPRESS', 'IMPRESSED', 'IMPRESSES', 'IMPRESSING', 'IMPRESSIVE', 'IMPRESSIVELY', 'IMPROVE', 'IMPROVED', 'IMPROVEMENT', 'IMPROVEMENTS', 'IMPROVES', 'IMPROVING', 'INCREDIBLE', 'INCREDIBLY', 'INFLUENTIAL', 'INFORMATIVE', 'INGENUITY', 'INNOVATE', 'INNOVATED', 'INNOVATES', 'INNOVATING', 'INNOVATION', 'INNOVATIONS', 'INNOVATIVE', 'INNOVATIVENESS', 'INNOVATOR', 'INNOVATORS', 'INSIGHTFUL', 'INSPIRATION', 'INSPIRATIONAL', 'INTEGRITY', 'INVENT', 'INVENTED', 'INVENTING', 'INVENTION', 'INVENTIONS', 'INVENTIVE', 'INVENTIVENESS', 'INVENTOR', 'INVENTORS', 'LEADERSHIP', 'LEADING', 'LOYAL', 'LUCRATIVE', 'MERITORIOUS', 'OPPORTUNITIES', 'OPPORTUNITY', 'OPTIMISTIC', 'OUTPERFORM', 'OUTPERFORMED', 'OUTPERFORMING', 'OUTPERFORMS', 'PERFECT', 'PERFECTED', 'PERFECTLY', 'PERFECTS', 'PLEASANT', 'PLEASANTLY', 'PLEASED', 'PLEASURE', 'PLENTIFUL', 'POPULAR', 'POPULARITY', 'POSITIVE', 'POSITIVELY', 'PREEMINENCE', 'PREEMINENT', 'PREMIER', 'PREMIERE', 'PRESTIGE', 'PRESTIGIOUS', 'PROACTIVE', 'PROACTIVELY', 'PROFICIENCY', 'PROFICIENT', 'PROFICIENTLY', 'PROFITABILITY', 'PROFITABLE', 'PROFITABLY', 'PROGRESS', 'PROGRESSED', 'PROGRESSES', 'PROGRESSING', 'PROSPERED', 'PROSPERING', 'PROSPERITY', 'PROSPEROUS', 'PROSPERS', 'REBOUND', 'REBOUNDED', 'REBOUNDING', 'RECEPTIVE', 'REGAIN', 'REGAINED', 'REGAINING', 'RESOLVE', 'REVOLUTIONIZE', 'REVOLUTIONIZED', 'REVOLUTIONIZES', 'REVOLUTIONIZING', 'REWARD', 'REWARDED', 'REWARDING', 'REWARDS', 'SATISFACTION', 'SATISFACTORILY', 'SATISFACTORY', 'SATISFIED', 'SATISFIES', 'SATISFY', 'SATISFYING', 'SMOOTH', 'SMOOTHING', 'SMOOTHLY', 'SMOOTHS', 'SOLVES', 'SOLVING', 'SPECTACULAR', 'SPECTACULARLY', 'STABILITY', 'STABILIZATION', 'STABILIZATIONS', 'STABILIZE', 'STABILIZED', 'STABILIZES', 'STABILIZING', 'STABLE', 'STRENGTH', 'STRENGTHEN', 'STRENGTHENED', 'STRENGTHENING', 'STRENGTHENS', 'STRENGTHS', 'STRONG', 'STRONGER', 'STRONGEST', 'SUCCEED', 'SUCCEEDED', 'SUCCEEDING', 'SUCCEEDS', 'SUCCESS', 'SUCCESSES', 'SUCCESSFUL', 'SUCCESSFULLY', 'SUPERIOR', 'SURPASS', 'SURPASSED', 'SURPASSES', 'SURPASSING', 'TRANSPARENCY', 'TREMENDOUS', 'TREMENDOUSLY', 'UNMATCHED', 'UNPARALLELED', 'UNSURPASSED', 'UPTURN', 'UPTURNS', 'VALUABLE', 'VERSATILE', 'VERSATILITY', 'VIBRANCY', 'VIBRANT', 'WIN', 'WINNER', 'WINNERS', 'WINNING', 'WORTHY']\n",
      "pos2:  ['able', 'abundance', 'abundant', 'acclaimed', 'accomplish', 'accomplished', 'accomplishes', 'accomplishing', 'accomplishment', 'accomplishments', 'achieve', 'achieved', 'achievement', 'achievements', 'achieves', 'achieving', 'adequately', 'advancement', 'advancements', 'advances', 'advancing', 'advantage', 'advantaged', 'advantageous', 'advantageously', 'advantages', 'alliance', 'alliances', 'assure', 'assured', 'assures', 'assuring', 'attain', 'attained', 'attaining', 'attainment', 'attainments', 'attains', 'attractive', 'attractiveness', 'beautiful', 'beautifully', 'beneficial', 'beneficially', 'benefit', 'benefited', 'benefiting', 'benefitted', 'benefitting', 'best', 'better', 'bolstered', 'bolstering', 'bolsters', 'boom', 'booming', 'boost', 'boosted', 'breakthrough', 'breakthroughs', 'brilliant', 'charitable', 'collaborate', 'collaborated', 'collaborates', 'collaborating', 'collaboration', 'collaborations', 'collaborative', 'collaborator', 'collaborators', 'compliment', 'complimentary', 'complimented', 'complimenting', 'compliments', 'conclusive', 'conclusively', 'conducive', 'confident', 'constructive', 'constructively', 'courteous', 'creative', 'creatively', 'creativeness', 'creativity', 'delight', 'delighted', 'delightful', 'delightfully', 'delighting', 'delights', 'dependability', 'dependable', 'desirable', 'desired', 'despite', 'destined', 'diligent', 'diligently', 'distinction', 'distinctions', 'distinctive', 'distinctively', 'distinctiveness', 'dream', 'easier', 'easily', 'easy', 'effective', 'efficiencies', 'efficiency', 'efficient', 'efficiently', 'empower', 'empowered', 'empowering', 'empowers', 'enable', 'enabled', 'enables', 'enabling', 'encouraged', 'encouragement', 'encourages', 'encouraging', 'enhance', 'enhanced', 'enhancement', 'enhancements', 'enhances', 'enhancing', 'enjoy', 'enjoyable', 'enjoyably', 'enjoyed', 'enjoying', 'enjoyment', 'enjoys', 'enthusiasm', 'enthusiastic', 'enthusiastically', 'excellence', 'excellent', 'excelling', 'excels', 'exceptional', 'exceptionally', 'excited', 'excitement', 'exciting', 'exclusive', 'exclusively', 'exclusiveness', 'exclusives', 'exclusivity', 'exemplary', 'fantastic', 'favorable', 'favorably', 'favored', 'favoring', 'favorite', 'favorites', 'friendly', 'gain', 'gained', 'gaining', 'gains', 'good', 'great', 'greater', 'greatest', 'greatly', 'greatness', 'happiest', 'happily', 'happiness', 'happy', 'highest', 'honor', 'honorable', 'honored', 'honoring', 'honors', 'ideal', 'impress', 'impressed', 'impresses', 'impressing', 'impressive', 'impressively', 'improve', 'improved', 'improvement', 'improvements', 'improves', 'improving', 'incredible', 'incredibly', 'influential', 'informative', 'ingenuity', 'innovate', 'innovated', 'innovates', 'innovating', 'innovation', 'innovations', 'innovative', 'innovativeness', 'innovator', 'innovators', 'insightful', 'inspiration', 'inspirational', 'integrity', 'invent', 'invented', 'inventing', 'invention', 'inventions', 'inventive', 'inventiveness', 'inventor', 'inventors', 'leadership', 'leading', 'loyal', 'lucrative', 'meritorious', 'opportunities', 'opportunity', 'optimistic', 'outperform', 'outperformed', 'outperforming', 'outperforms', 'perfect', 'perfected', 'perfectly', 'perfects', 'pleasant', 'pleasantly', 'pleased', 'pleasure', 'plentiful', 'popular', 'popularity', 'positive', 'positively', 'preeminence', 'preeminent', 'premier', 'premiere', 'prestige', 'prestigious', 'proactive', 'proactively', 'proficiency', 'proficient', 'proficiently', 'profitability', 'profitable', 'profitably', 'progress', 'progressed', 'progresses', 'progressing', 'prospered', 'prospering', 'prosperity', 'prosperous', 'prospers', 'rebound', 'rebounded', 'rebounding', 'receptive', 'regain', 'regained', 'regaining', 'resolve', 'revolutionize', 'revolutionized', 'revolutionizes', 'revolutionizing', 'reward', 'rewarded', 'rewarding', 'rewards', 'satisfaction', 'satisfactorily', 'satisfactory', 'satisfied', 'satisfies', 'satisfy', 'satisfying', 'smooth', 'smoothing', 'smoothly', 'smooths', 'solves', 'solving', 'spectacular', 'spectacularly', 'stability', 'stabilization', 'stabilizations', 'stabilize', 'stabilized', 'stabilizes', 'stabilizing', 'stable', 'strength', 'strengthen', 'strengthened', 'strengthening', 'strengthens', 'strengths', 'strong', 'stronger', 'strongest', 'succeed', 'succeeded', 'succeeding', 'succeeds', 'success', 'successes', 'successful', 'successfully', 'superior', 'surpass', 'surpassed', 'surpasses', 'surpassing', 'transparency', 'tremendous', 'tremendously', 'unmatched', 'unparalleled', 'unsurpassed', 'upturn', 'upturns', 'valuable', 'versatile', 'versatility', 'vibrancy', 'vibrant', 'win', 'winner', 'winners', 'winning', 'worthy']\n"
     ]
    }
   ],
   "source": [
    "with open('word/pos.txt', 'r') as f:\n",
    "    positive_words = [line.strip() for line in f]\n",
    "    print('pos1: ', positive_words)\n",
    "    positive_words = [x.lower() for x in positive_words]\n",
    "    print('pos2: ', positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
